import { ProviderConfig } from './providerAdapter.interface';
import { getProvider } from '../providers';

/**
 * Adaptador gen√©rico unificado para provedores de LLM.
 * 
 * Esta classe fornece uma interface consistente para interagir com diferentes
 * provedores de modelos de linguagem, abstraindo as diferen√ßas entre APIs
 * e permitindo troca f√°cil entre provedores.
 * 
 * ## Funcionalidades Principais
 * 
 * - **Interface Unificada**: API consistente independente do provedor
 * - **Auto-detec√ß√£o**: Detecta automaticamente o provedor baseado no modelo
 * - **Fallback Inteligente**: Usa openaiCompatible para modelos desconhecidos com baseUrl
 * - **Logging Detalhado**: Log completo do prompt para debugging
 * - **Configura√ß√£o Flex√≠vel**: Suporte a todos os par√¢metros via ProviderConfig
 * 
 * ## Auto-detec√ß√£o de Provedores
 * 
 * O ProviderAdapter infere o provedor baseado no prefixo do modelo:
 * - `gpt-4` ‚Üí OpenAI
 * `claude-3-sonnet` ‚Üí OpenAI Compatible (se baseUrl fornecida)
 * - `meta-llama/llama-3.1-70b` ‚Üí OpenAI Compatible (se baseUrl fornecida)
 * 
 * @example
 * ```typescript
 * // Uso b√°sico
 * const config: ProviderConfig = {
 *   model: 'gpt-4',
 *   messages: [{ role: 'user', content: 'Ol√°!' }],
 *   apiKey: 'sua-api-key'
 * };
 * 
 * const response = await ProviderAdapter.chatCompletion(config);
 * console.log(response.content);
 * 
 * // Com provedor compat√≠vel
 * const compatibleConfig: ProviderConfig = {
 *   model: 'claude-3-sonnet',
 *   messages: [...],
 *   apiKey: 'sua-api-key',
 *   baseUrl: 'https://api.anthropic.com'
 * };
 * 
 * const response2 = await ProviderAdapter.chatCompletion(compatibleConfig);
 * ```
 * 
 * @see {@link ProviderConfig} Para configura√ß√£o completa
 * @see {@link ProviderRegistry} Para registro de provedores
 */
export class ProviderAdapter {
  /** 
   * Executa uma chamada de chat completion usando o provedor apropriado.
   * 
   * Este m√©todo √© o ponto de entrada principal do ProviderAdapter. Ele:
   * 1. Infere o provedor baseado no modelo
   * 2. Aplica defaults para par√¢metros n√£o especificados
   * 3. Implementa fallback para provedores compat√≠veis
   * 4. Loga informa√ß√µes detalhadas para debugging
   * 5. Chama o provedor apropriado com configura√ß√£o unificada
   * 
   * @param config Configura√ß√£o completa do provedor.
   * Deve incluir model, messages, apiKey e pode incluir par√¢metros opcionais.
   * 
   * @returns Resposta do provedor no formato unificado.
   * 
   * @throws {Error} Se o provedor n√£o estiver registrado
   * @throws {Error} Se o provedor n√£o implementar chatCompletion
   * @throws {Error} Se baseUrl for necess√°ria mas n√£o fornecida
   * 
   * @example
   * ```typescript
   * // Configura√ß√£o b√°sica
   * const response = await ProviderAdapter.chatCompletion({
   *   model: 'gpt-4',
   *   messages: [{ role: 'user', content: 'Explique IA' }],
   *   apiKey: 'sk-...',
   *   temperature: 0.7,
   *   maxTokens: 1000
   * });
   * 
   * // Com streaming
   * const streamingConfig = {
   *   model: 'gpt-4',
   *   messages: [...],
   *   apiKey: 'sk-...',
   *   stream: true
   * };
   * 
   * const streamResponse = await ProviderAdapter.chatCompletion(streamingConfig);
   * for await (const chunk of streamResponse) {
   *   process.stdout.write(chunk.content);
   * }
   * ```
   * 
   * @remarks
   * - O nome do provedor √© extra√≠do do prefixo do modelo (antes do primeiro '-')
   * - Par√¢metros n√£o especificados usam defaults inteligentes
   * - Modelos desconhecidos com baseUrl s√£o tratados como openaiCompatible
   * - Log detalhado √© emitido para debugging (pode ser desabilitado em produ√ß√£o)
   * 
   * @see {@link ProviderConfig} Para formato da configura√ß√£o
   */
  static async chatCompletion(config: ProviderConfig): Promise<any> {
    // Inferir nome do provedor baseado no modelo
    let providerName = config.model.split('-')[0];

    // Aplicar defaults para par√¢metros n√£o especificados
    config.temperature = config.temperature ?? 0.7; // Default comum
    config.maxTokens = config.maxTokens ?? 2048;    // Default comum

    // Fallback inteligente: se provedor n√£o existe mas temos baseUrl,
    // assumir provedor compat√≠vel com OpenAI (ex: OpenRouter, Claude, etc.)
    if (!ProviderAdapter.hasProvider(providerName) && config.baseUrl) {
      providerName = 'openaiCompatible';
    }

    // Log detalhado para debugging
    ProviderAdapter._logPromptDetails(providerName, config);

    // Obter e instanciar o provedor
    const ProviderClass: any = getProvider(providerName);
    const provider = new ProviderClass(config.apiKey);
    
    // Extrair nome do modelo sem o prefixo do provedor
    const model = config.model.startsWith(providerName + '-')
      ? config.model.slice(providerName.length + 1)
      : config.model;

    // Validar que o provedor implementa o m√©todo necess√°rio
    if (typeof provider.chatCompletion !== 'function') {
      throw new Error(`Provedor para o modelo ${config.model} n√£o implementa o m√©todo chatCompletion`);
    }

    // Chamar o provedor com configura√ß√£o unificada
    return provider.chatCompletion({ ...config, model });
  }

  /** 
   * Verifica se um provedor est√° registrado e dispon√≠vel.
   * 
   * @param providerName Nome do provedor a ser verificado.
   * 
   * @returns true se o provedor estiver registrado, false caso contr√°rio.
   * 
   * @example
   * ```typescript
   * if (ProviderAdapter.hasProvider('openai')) {
   *   console.log('OpenAI est√° dispon√≠vel');
   * }
   * 
   * if (ProviderAdapter.hasProvider('anthropic')) {
   *   console.log('Anthropic est√° dispon√≠vel');
   * } else {
   *   console.log('Anthropic n√£o est√° registrado');
   * }
   * ```
   */
  static hasProvider(providerName: string): boolean {
    try {
      getProvider(providerName);
      return true;
    } catch {
      return false;
    }
  }

  /** 
   * Log detalhado das informa√ß√µes do prompt para debugging.
   * 
   * @private
   * @param providerName Nome do provedor sendo usado
   * @param config Configura√ß√£o completa
   */
  private static _logPromptDetails(providerName: string, config: ProviderConfig): void {
    console.log('\n' + '='.repeat(80));
    console.log('ü§ñ PROMPT COMPLETO ANTES DA CHAMADA AO LLM');
    console.log('='.repeat(80));
    console.log(`üìã Provider: ${providerName}`);
    console.log(`üéØ Modelo: ${config.model}`);
    console.log(`üå°Ô∏è  Temperatura: ${config.temperature || 'default'}`);
    console.log(`üî¢ Max Tokens: ${config.maxTokens || 'default'}`);
    console.log('='.repeat(80));

    // Log do system prompt completo
    if (config.systemPrompt) {
      console.log('\nüìÑ SYSTEM PROMPT COMPLETO:');
      console.log('-'.repeat(60));
      console.log(config.systemPrompt);
      console.log('-'.repeat(60));
    }

    // Log das mensagens (preview)
    if (config.messages && config.messages.length > 0) {
      console.log('\nüí¨ MENSAGENS DA CONVERSA:');
      console.log('-'.repeat(60));
      config.messages.forEach((msg, index) => {
        console.log(`${index + 1}. [${msg.role}] ${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}`);
      });
      console.log('-'.repeat(60));
    }
  }
}
